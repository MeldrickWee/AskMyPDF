{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain, ConversationalRetrievalChain\n",
    "from langchain.chains.qa_with_sources import load_qa_with_sources_chain\n",
    "from langchain.llms import OpenAI\n",
    "from langchain import LLMChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"../data/pdf_data/AI-Practitioner-Handbook.pdf\")\n",
    "#loader = OnlinePDFLoader(\"https://epoch.aisingapore.org/wp-content/uploads/2023/03/AI-Practitioner-Handbook-20230324.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')\n",
    "\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI_API_KEY = 'xx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# create a GPT-4 encoder instance\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "total_word_count = sum(len(doc.page_content.split()) for doc in texts)\n",
    "total_token_count = sum(len(enc.encode(doc.page_content)) for doc in texts)\n",
    "\n",
    "print(f\"\\nTotal word count: {total_word_count}\")\n",
    "print(f\"\\nEstimated tokens: {total_token_count}\")\n",
    "print(f\"\\nEstimated cost of embedding: ${total_token_count * 0.0004 / 1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "# vector_store = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# from IPython.display import display, Markdown\n",
    "\n",
    "# search_result = vector_store.similarity_search_with_score(\"who is this pdf for?\")\n",
    "# search_result\n",
    "\n",
    "# line_separator = \"\\n\"# {line_separator}Source: {r[0].metadata['source']}{line_separator}Score:{r[1]}{line_separator}\n",
    "# display(Markdown(f\"\"\"\n",
    "# ## Search results:{line_separator}\n",
    "# {line_separator.join([\n",
    "#   f'''\n",
    "#   ### Source:{line_separator}{r[0].metadata['source']}{line_separator}\n",
    "#   #### Score:{line_separator}{r[1]}{line_separator}\n",
    "#   #### Content:{line_separator}{r[0].page_content}{line_separator}\n",
    "#   '''\n",
    "#   for r in search_result\n",
    "# ])}\n",
    "# \"\"\"))\n",
    "\n",
    "# vector_store.save_local(\"C:/Users/meldr/aiap/langchain-question-answer/data/vector_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_template=\"\"\"Use the following pieces of context to answer the users question.\n",
    "Take note of the sources and include them in the answer in the format: \"SOURCES: source1 source2\", use \"SOURCES\" in capital letters regardless of the number of sources.\n",
    "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
    "----------------\n",
    "{summaries}\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"../data/vector_data/\"\n",
    "if os.path.exists(path):\n",
    "  vector_store = FAISS.load_local(\n",
    "      path,\n",
    "      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "  )\n",
    "else:\n",
    "  print(f\"Missing files. Upload index.faiss and index.pkl files to {path} directory first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)  # Modify model_name if you have access to GPT-4\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_result(result):\n",
    "    output_text = f\"\"\"### Question: \n",
    "    {query}\n",
    "    ### Answer: \n",
    "    {result['answer']}\n",
    "    ### Sources: \n",
    "    {result['sources']}\n",
    "    ### All relevant sources:\n",
    "    {' '.join(list(set([doc.metadata['source'] for doc in result['source_documents']])))}\n",
    "    \"\"\"\n",
    "    display(Markdown(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the different robustness testing tools?\"\n",
    "result = chain(query)\n",
    "print_result(result)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['sources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result['source_documents']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/vector_data/\"\n",
    "vector_store = FAISS.load_local(path, OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_template = \"\"\"Use the following pieces of context to answer the users question.\\\n",
    "No matter what the question is, you should always answer it in the context of the AI Practitioner Handbook.\\\n",
    "Even if the question does not end in a question mark, you should still answer it as if it were a question.\\\n",
    "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\\\n",
    "If the question is not related to the AI Practitioner Handbook, just say that \"I don't know\".\\\n",
    "----------------\n",
    "{summaries}\"\"\"\n",
    "\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\"),\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "llm = OpenAI(temperature=0, openai_api_key=openai_api_key)\n",
    "#question_generator = LLMChain(llm=llm, prompt=prompt)\n",
    "#doc_chain = load_qa_with_sources_chain(llm, chain_type=\"stuff\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.prompt import PromptTemplate\n",
    "\n",
    "_template = \"\"\"Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\n",
    "You can assume the question about the most recent state of the AI Practioner Handbook.\n",
    "Chat History:\n",
    "{chat_history}\n",
    "Follow Up Input: {question}\n",
    "Standalone question:\"\"\"\n",
    "\n",
    "CONDENSE_QUESTION_PROMPT = PromptTemplate.from_template(_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['chat_history', 'question'], output_parser=None, partial_variables={}, template='Given the following conversation and a follow up question, rephrase the follow up question to be a standalone question.\\nYou can assume the question about the most recent state of the AI Practioner Handbook.\\nChat History:\\n{chat_history}\\nFollow Up Input: {question}\\nStandalone question:', template_format='f-string', validate_template=True)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CONDENSE_QUESTION_PROMPT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    #question_generator=question_generator,\n",
    "    #combine_docs_chain=doc_chain,\n",
    "    verbose=True,\n",
    "    return_source_documents=True,\n",
    "    condense_question_prompt=CONDENSE_QUESTION_PROMPT,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history = []\n",
    "query = \"What is the role of an ai engineer?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What is the role of an ai engineer?',\n",
       " 'chat_history': [],\n",
       " 'answer': ' The role of an AI engineer is to build a solution for another company to take over and implement. They assess whether the client has the capability to take over the final solution, integrate and maintain it, as the goal is to enable companies to build their own AI capabilities in the long run. AI engineers also participate in pre-project scoping and gauge if the client is capable of taking over the AI solution.',\n",
       " 'source_documents': [Document(page_content='2.2 How can I build an effective AI development team?\\n\\nContributor: Kenny WJ Chua, Senior AI Engineer\\n\\n2.2.1 Introduction\\n\\nThe responsbilities of a technical lead are different from those of an individual contributor. Engineers, especially those\\n\\nwho are who are unfamiliar with leadership responsibilities, may face a learning curve in fulfilling these responsibilities.\\n\\nA technical lead indirectly delivers an AI project on time and on target by building an effective AI development team.\\n\\nThis article provides suggestions on promoting effective teams by contextualising general leadership principles.\\n\\nIn AISG, an engineer serves as technical lead for a small team of apprentices (i.e., ‘developers’). Therefore, the contents\\n\\nof this article would be useful to any AI practitioner who is in a similar leadership role.\\n\\nThis article requires some basic knowledge of a AI project life cycle and typical activities that occur in each stage. The', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='ticeship Programme) working on the project full-time for the duration of the project. They are supported by Project\\n\\nManagers and the AI and ML Ops teams to deliver the project on time, and with the right infrastructure and architecture\\n\\npowered by established CI/CD pipelines.\\n\\nOur AI Engineers come from diverse academic disciplines and industry experience. In fact, many of our AI Engineers\\n\\nare hired from AI Apprentice cohorts. This handbook will provide new AI Engineers with a quick guide on our best\\n\\npractices to help them quickly become productive.\\n\\nConclusion\\n\\nSince 2017, we have engaged more than 600 companies, approved more than 1003 projects and completed more than 60\\n\\nof these AI projects under the 100E programme, and trained more than 250 AI Apprentices.\\n\\n2 Who are the AI Apprentices? See How Did AI Singapore Build a “200” Strong All-Singaporean AI Engineering Team With the Blue Ocean\\n\\nStrategy?\\n\\n3 Information to date\\n\\nCONTENTS\\n\\n3\\n\\nAI Practitioner Handbook', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='Contributor: Joy Lin, Senior AI Technical Consultant\\n\\nAI Practitioner Handbook\\n\\n1.5.1 Who is this for?\\n\\nThis article is aimed at AI engineers in an organisation like AI Singapore, who are building a solution for another company\\n\\n(henceforth referred to as the client) to take over and implement. In AI Singapore, the business development/presales\\n\\nteam, together with the AI engineer, scope for feasible AI projects. In doing so, they assess whether the client has the\\n\\ncapability to take over the final solution, integrate and maintain it, as the goal is to enable companies to build their own\\n\\nAI capabilities in the long run. Assuming that the client’s proposed AI solution has an established business value and is\\n\\nethical, this article narrows the focus to the technical aspects of AI readiness.\\n\\n1.5.2 Why does AI engineer need to assess client’s AI capabilities?\\n\\nWhen participating in pre-project scoping, it is beneficial for you to gauge if the client is capable of taking over your', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='We envisioned this handbook as a useful guide for new AI Engineers joining AI Singapore and to quickly come up to speed\\n\\non how we execute AI projects. However, the information contained here would also appeal to any new AI Engineers and\\n\\nManagers deploying their first AI project into production.\\n\\nDelivering production AI models goes beyond building AI models in Jupyter notebooks. It includes preliminary data\\n\\nidentification, cleaning and curation, followed by building, training and testing the models and finally deploying the model.\\n\\nThroughout the process, AI and ML Ops play a fundamental role to enable the whole end-to-end process.\\n\\nThere are many excellent books and resources on various AI algorithms, and we will not replicate them here. Instead, we\\n\\nwill focus on the best practices and knowledge required to deliver an AI project from end to end.\\n\\nCONTENTS\\n\\n1\\n\\nAI Practitioner Handbook\\n\\nIdentifying AI Ready Projects', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'})]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"How can he build the team?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can he build the team?',\n",
       " 'chat_history': [('What is the role of an ai engineer?',\n",
       "   'According to the context provided, an AI engineer is responsible for building and delivering AI projects on time and on target by building an effective AI development team. They work as technical leads for a small team of apprentices (i.e., ‘developers’), and they are supported by Project Managers and the AI and ML Ops teams to deliver the project on time, and with the right infrastructure and architecture powered by established CI/CD pipelines. Their responsibilities include preliminary data identification, cleaning and curation, followed by building, training and testing the models and finally deploying the model.')],\n",
       " 'answer': 'The article provides suggestions on promoting effective teams by contextualizing general leadership principles. A technical lead indirectly delivers an AI project on time and on target by building an effective AI development team. The article requires some basic knowledge of an AI project life cycle and typical activities that occur in each stage. The technical lead can model the way by demonstrating values and practices that he/she espouses. For example, a technical lead can cultivate a team habit of writing well-structured and documented code by taking on a few of such tasks himself/herself. This may be particularly fruitful when onboarding a new team of junior developers. The article also suggests considering the organizational readiness of the client, such as whether there is an existing technical team who is able to integrate and maintain the AI models, whether the client’s management is supportive of AI projects and team expansion if necessary, and whether the client’s management and key stakeholders allow room for experimentation and development.',\n",
       " 'source_documents': [Document(page_content='2.2 How can I build an effective AI development team?\\n\\nContributor: Kenny WJ Chua, Senior AI Engineer\\n\\n2.2.1 Introduction\\n\\nThe responsbilities of a technical lead are different from those of an individual contributor. Engineers, especially those\\n\\nwho are who are unfamiliar with leadership responsibilities, may face a learning curve in fulfilling these responsibilities.\\n\\nA technical lead indirectly delivers an AI project on time and on target by building an effective AI development team.\\n\\nThis article provides suggestions on promoting effective teams by contextualising general leadership principles.\\n\\nIn AISG, an engineer serves as technical lead for a small team of apprentices (i.e., ‘developers’). Therefore, the contents\\n\\nof this article would be useful to any AI practitioner who is in a similar leadership role.\\n\\nThis article requires some basic knowledge of a AI project life cycle and typical activities that occur in each stage. The', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='2.3 How can I cultivate a cohesive AI development team? . . . . .\\n\\n2.4 What kind of engineering principles can I set for my development team? . . . .\\n\\n2.5 How might we simplify and translate technical jargon? . . . . .\\n\\n. . . . .\\n\\n. . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n.\\n\\n. . . . . . . . . . . . . . . . . . . . . . . .\\n\\n. . . . .\\n\\n. . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . . . . . .\\n\\n. . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . . . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . . . . . .\\n\\n. .\\n\\n. . . .\\n\\n.\\n\\n. .\\n\\n.\\n\\n3 Collaborative Development Platforms\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n3.1 Overview .\\n\\n. . .\\n\\n3.2 What are the key platforms required for collaborative ML development? . . . .\\n\\n3.3 What are some considerations in setting up a project repository? . . . .\\n\\n. . . . . . . . . . . . . . . . . . . . . . . .\\n\\n. .\\n\\n. .\\n\\n. . .\\n\\n. . . . . . .\\n\\n. . . . . . .\\n\\n. . .\\n\\n. . . . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n4 Literature Review\\n\\n.\\n\\n4.1 Overview .\\n\\n4.2 What are some of the factors to consider during literature review? . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . .', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='solution for deployment. Most AI projects end up in failures during deployment phase due to three main reasons:\\n\\n1. Technical hurdles in implementing/integrating model into existing operations\\n\\n2. Decision makers unwilling to approve change to existing operations\\n\\n3. Model performance not considered strong enough by decision makers\\n\\n1.5.3 What can the AI engineer look out for?\\n\\nTo ensure a successful project, let us focus on three broad areas to help you assess the client’s AI readiness level.\\n\\n1. Organisational readiness\\n\\nIs there an existing technical team who is able to integrate and maintain the AI models? If not, what are the\\n\\nclient’s plans to hire the necessary resources?\\n\\nIs the client’s management supportive of AI projects and team expansion if necessary?\\n\\nDo the client’s management and key stakeholders allow room for experimentation and development?\\n\\nAs an organisation looking to use AI solutions, the client’s management should understand that model building and main-', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='article on building a cohesive AI development team may also be useful for engineers in the role of technical lead.\\n\\n2.2.2 Model the way\\n\\nA technical lead may have a specific mental picture of the deliverables and ideal approach for a given task, but the end\\n\\nresult may differ when delegated to developers. One possible reason is imperfect communication, such that developers do\\n\\nnot entirely understand the specifications that have been laid out (hence the need for architecture diagrams). Alternatively,\\n\\nless experienced developers may not understand the need to adhere strictly to certain best practices.\\n\\nIn such a context, it is important for the technical lead to be able to demonstrate some of these values and practices that\\n\\nhe/she espouses. For example, a technical lead can cultivate a team habit of writing well-structured and documented code\\n\\nby taking on a few of such tasks himself/herself. This may be particularly fruitful when onboarding a new team of junior', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'})]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"How does he develop and deloy the solution?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How does he develop and deloy the solution?',\n",
       " 'chat_history': [('What is the role of an ai practitioner?',\n",
       "   \" An AI Practitioner is someone who is responsible for developing and deploying AI projects. This includes tasks such as identifying AI ready projects, building and training models, and deploying models into production. AI Practitioners also need to assess the client's AI capabilities to ensure that they are able to take over the final solution, integrate and maintain it.\"),\n",
       "  ('How can he build the team?',\n",
       "   \" Building an AI team requires recruiting the right people, setting engineering principles, cultivating a cohesive team, and simplifying and translating technical jargon. Additionally, setting up a project repository and assessing the client's AI readiness level are important considerations.\")],\n",
       " 'answer': ' An AI Practitioner develops and deploys an AI solution by first identifying an AI-ready project, then building an effective AI development team, and finally following best practices for model building, training, testing, and deployment.',\n",
       " 'source_documents': [Document(page_content='solution for deployment. Most AI projects end up in failures during deployment phase due to three main reasons:\\n\\n1. Technical hurdles in implementing/integrating model into existing operations\\n\\n2. Decision makers unwilling to approve change to existing operations\\n\\n3. Model performance not considered strong enough by decision makers\\n\\n1.5.3 What can the AI engineer look out for?\\n\\nTo ensure a successful project, let us focus on three broad areas to help you assess the client’s AI readiness level.\\n\\n1. Organisational readiness\\n\\nIs there an existing technical team who is able to integrate and maintain the AI models? If not, what are the\\n\\nclient’s plans to hire the necessary resources?\\n\\nIs the client’s management supportive of AI projects and team expansion if necessary?\\n\\nDo the client’s management and key stakeholders allow room for experimentation and development?\\n\\nAs an organisation looking to use AI solutions, the client’s management should understand that model building and main-', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='We envisioned this handbook as a useful guide for new AI Engineers joining AI Singapore and to quickly come up to speed\\n\\non how we execute AI projects. However, the information contained here would also appeal to any new AI Engineers and\\n\\nManagers deploying their first AI project into production.\\n\\nDelivering production AI models goes beyond building AI models in Jupyter notebooks. It includes preliminary data\\n\\nidentification, cleaning and curation, followed by building, training and testing the models and finally deploying the model.\\n\\nThroughout the process, AI and ML Ops play a fundamental role to enable the whole end-to-end process.\\n\\nThere are many excellent books and resources on various AI algorithms, and we will not replicate them here. Instead, we\\n\\nwill focus on the best practices and knowledge required to deliver an AI project from end to end.\\n\\nCONTENTS\\n\\n1\\n\\nAI Practitioner Handbook\\n\\nIdentifying AI Ready Projects', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='AI Practitioner Handbook\\n\\nContributed by Engineers from AI Singapore\\n\\nEdited by Kenny WJ Chua, Ryzal Kamis,\\n\\nSiavash Sakhavi, Anand Natarajan, Kevin Oh,\\n\\nNajib Ninaba, Kim Hock Ng and Laurence Liew\\n\\nMar 24, 2023\\n\\nCONTENTS\\n\\n.\\n\\n.\\n\\n.\\n\\n1 Pre-project Phase\\n\\n1.1 Overview .\\n\\n.\\n\\n1.2 How can business challenges be translated into AI problems? . . . . .\\n\\n1.3 What are some data considerations when framing an AI project?\\n\\n1.4 What are the considerations for reducing technical debt? . . . . .\\n\\n1.5 How can an engineer assess a client’s AI readiness? . . . . .\\n\\n. . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . .\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n. . . . . . . . . . . . . . . . . . . . . . . .\\n\\n. . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . . .\\n\\n. . . . .\\n\\n. . . . . . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . .\\n\\n. . . . .\\n\\n. . .\\n\\n. . . . .\\n\\n. .\\n\\n. . . .\\n\\n. . . . . .\\n\\n.\\n\\n. . . .\\n\\n. . . . . .\\n\\n2 Project Management & Technical Leadership\\n\\n.\\n\\n.\\n\\n. . .\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n.\\n\\n2.1 Overview .\\n\\n.\\n\\n.\\n\\n2.2 How can I build an effective AI development team? . . . . .', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='ticeship Programme) working on the project full-time for the duration of the project. They are supported by Project\\n\\nManagers and the AI and ML Ops teams to deliver the project on time, and with the right infrastructure and architecture\\n\\npowered by established CI/CD pipelines.\\n\\nOur AI Engineers come from diverse academic disciplines and industry experience. In fact, many of our AI Engineers\\n\\nare hired from AI Apprentice cohorts. This handbook will provide new AI Engineers with a quick guide on our best\\n\\npractices to help them quickly become productive.\\n\\nConclusion\\n\\nSince 2017, we have engaged more than 600 companies, approved more than 1003 projects and completed more than 60\\n\\nof these AI projects under the 100E programme, and trained more than 250 AI Apprentices.\\n\\n2 Who are the AI Apprentices? See How Did AI Singapore Build a “200” Strong All-Singaporean AI Engineering Team With the Blue Ocean\\n\\nStrategy?\\n\\n3 Information to date\\n\\nCONTENTS\\n\\n3\\n\\nAI Practitioner Handbook', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'})]}"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new ConversationalRetrievalChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "chat_history.append((query, result[\"answer\"]))\n",
    "query = \"How can he test models?\"\n",
    "result = chain({\"question\": query, \"chat_history\": chat_history})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'How can he test models?',\n",
       " 'chat_history': [('What is the role of an ai practitioner?',\n",
       "   \" An AI Practitioner is someone who is responsible for developing and deploying AI projects. This includes tasks such as identifying AI ready projects, building and training models, and deploying models into production. AI Practitioners also need to assess the client's AI capabilities to ensure that they are able to take over the final solution, integrate and maintain it.\"),\n",
       "  ('How can he build the team?',\n",
       "   \" Building an AI team requires recruiting the right people, setting engineering principles, cultivating a cohesive team, and simplifying and translating technical jargon. Additionally, setting up a project repository and assessing the client's AI readiness level are important considerations.\"),\n",
       "  ('How does he develop and deloy the solution?',\n",
       "   ' An AI Practitioner develops and deploys an AI solution by first identifying an AI-ready project, then building an effective AI development team, and finally following best practices for model building, training, testing, and deployment.')],\n",
       " 'answer': ' The best practices for testing models include testing the API calls, checking for algorithmic correctness, testing for model stability, deterministically seeding the random number generator, writing integration tests, and logging.',\n",
       " 'source_documents': [Document(page_content='Apart from testing code, you should test your model as well. Below are several things to test your model for.\\n\\na. API calls\\n\\nOne of the things you can test is to test the API calls. As ML frameworks and libraries are constantly getting upgraded,\\n\\nyou need to make sure the API calls are working as expected. Write unit tests with random input data running through\\n\\nthe API call (ie. a single step of gradient descent).\\n\\nTo reduce the risk of API calls breaking, you can version the libraries used; eg. create a software enviroment with specific\\n\\nand static dependency versions recorded in a requirements file.\\n\\nb. Algorithmic correctness\\n\\nOther than testing the API calls, you should make sure your model’s performance is not due to luck.\\n\\nTo check for algorithmic correctness you can:\\n\\nVerify that the loss decreases with increasing training iterations.\\n\\nVerify that without regularization, the training loss is low enough. If your model is complex enough, it will capture', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='information from the training data.\\n\\nTest specific subcomputations of your algorithm. (e.g. test that neural network weights are updated with every\\n\\npass).\\n\\n6.3. How can I maximise model reproducibility?\\n\\n59\\n\\nAI Practitioner Handbook\\n\\nc. Test that model is stable\\n\\nA stable model would be reproducible as it produces consistent results. When training a neural network, your weights and\\n\\nlayer outputs should not be NaN or Inf. A given layer should also not return zeroes for more than half of its outputs.\\n\\nWrite tests to check for NaN and Inf values in your weights and layer outputs.\\n\\nFurthermore, perform sensitivity analysis on the hyperparameters of your ML system to ensure system hyperparameter\\n\\nstability.\\n\\n2. Deterministically seed the random number generator (RNG)\\n\\nApart from fixing the seed value for data splits, you should use a fixed seed value across all the libraries in the code', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='stores help in mainining model versions.\\n\\n4. Integration tests\\n\\nAs a ML pipeline consiste of several components, tests that runs the entire pipeline end-to-end should be written. To run\\n\\nintegration tests more quickly, train on a subset of the data or with a simpler model.\\n\\n5. Logging\\n\\nIt is important to log everything used in ML modelling (e.g. model parameters, hyperparameters, feature transformations,\\n\\norder of features, method to select them, structure of the ensemble (if applicable), hardware specifications). This would\\n\\nhelp to recreate the environment the model was created in. Furthermore, dependency changes (e.g. changes in API calls)\\n\\nshould be recorded.\\n\\n6.3.3 Inherent stochasticity\\n\\nAs mentioned earlier, the ML pipeline is not always entirely reproducible. Inherent stochasticity exists in some compo-\\n\\nnents, such as when using GPUs, randomness in backend libraries, and stochastic ML algorithms. In order to improve', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       "  Document(page_content='deciding whether the model is robust or not robust. There is always a need for comparison between models versions\\n\\n(especially for adversarial robustness testing). Testing the robustness of one model does not tell you anything other than\\n\\nwhere it fails. Lastly, you might find that standard accuracy might have a trade off with robustness, this is still (as of\\n\\nwriting) an area under research.\\n\\nReference(s):\\n\\nBIML Architectural Risk Analysis\\n\\nSingapore’s Model AI Governance Framework\\n\\nDeepFool\\n\\nIBM-ART\\n\\nMicrosoft CheckList\\n\\nTextAttack\\n\\nTest ML like software\\n\\nMetamorphic Testing\\n\\n6.5 How do I select classification metrics?\\n\\nContributor(s): Lee Xin Jie, Senior AI Engineer (100E), Er YuYang, Senior AI Engineer (100E)\\n\\n6.5.1 Introduction\\n\\nThe common classification evaluation metrics includes accuracy, confusion matrix, precision, recall, F1, ROC & AUC,\\n\\nprecision-recall curve.', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'})]}"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "questionanswer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
