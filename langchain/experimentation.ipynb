{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"../data/pdf_data/AI-Practitioner-Handbook.pdf\")\n",
    "#loader = OnlinePDFLoader(\"https://epoch.aisingapore.org/wp-content/uploads/2023/03/AI-Practitioner-Handbook-20230324.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')\n",
    "\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#OPENAI_API_KEY = 'xx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# create a GPT-4 encoder instance\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "total_word_count = sum(len(doc.page_content.split()) for doc in texts)\n",
    "total_token_count = sum(len(enc.encode(doc.page_content)) for doc in texts)\n",
    "\n",
    "print(f\"\\nTotal word count: {total_word_count}\")\n",
    "print(f\"\\nEstimated tokens: {total_token_count}\")\n",
    "print(f\"\\nEstimated cost of embedding: ${total_token_count * 0.0004 / 1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "# vector_store = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# from IPython.display import display, Markdown\n",
    "\n",
    "# search_result = vector_store.similarity_search_with_score(\"who is this pdf for?\")\n",
    "# search_result\n",
    "\n",
    "# line_separator = \"\\n\"# {line_separator}Source: {r[0].metadata['source']}{line_separator}Score:{r[1]}{line_separator}\n",
    "# display(Markdown(f\"\"\"\n",
    "# ## Search results:{line_separator}\n",
    "# {line_separator.join([\n",
    "#   f'''\n",
    "#   ### Source:{line_separator}{r[0].metadata['source']}{line_separator}\n",
    "#   #### Score:{line_separator}{r[1]}{line_separator}\n",
    "#   #### Content:{line_separator}{r[0].page_content}{line_separator}\n",
    "#   '''\n",
    "#   for r in search_result\n",
    "# ])}\n",
    "# \"\"\"))\n",
    "\n",
    "# vector_store.save_local(\"C:/Users/meldr/aiap/langchain-question-answer/data/vector_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_template=\"\"\"Use the following pieces of context to answer the users question.\n",
    "Take note of the sources and include them in the answer in the format: \"SOURCES: source1 source2\", use \"SOURCES\" in capital letters regardless of the number of sources.\n",
    "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
    "----------------\n",
    "{summaries}\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"../data/vector_data/\"\n",
    "if os.path.exists(path):\n",
    "  vector_store = FAISS.load_local(\n",
    "      path,\n",
    "      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "  )\n",
    "else:\n",
    "  print(f\"Missing files. Upload index.faiss and index.pkl files to {path} directory first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)  # Modify model_name if you have access to GPT-4\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_result(result):\n",
    "    output_text = f\"\"\"### Question: \n",
    "    {query}\n",
    "    ### Answer: \n",
    "    {result['answer']}\n",
    "    ### Sources: \n",
    "    {result['sources']}\n",
    "    ### All relevant sources:\n",
    "    {' '.join(list(set([doc.metadata['source'] for doc in result['source_documents']])))}\n",
    "    \"\"\"\n",
    "    display(Markdown(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Question: \n",
       "    What are the different robustness testing tools?\n",
       "    ### Answer: \n",
       "    There are several robustness testing tools mentioned in the AI Practitioner Handbook, including IBM ART, TextAttack, and Microsoft CheckList. The data type and model type supported by each tool varies. IBM ART is generally used for arrays of numeric data (i.e. images, audio), but is attack specific. TextAttack is used for text, while Microsoft CheckList can be used for any arbitrary format (as the mutation functions can be user-defined). The expectation functions can also be user-defined for any data type. For more information on robustness testing tools, you can refer to Chapter 6.4.4 of the AI Practitioner Handbook. (\n",
       "    ### Sources: \n",
       "    ../pdf_data/AI-Practitioner-Handbook.pdf)\n",
       "    ### All relevant sources:\n",
       "    ../pdf_data/AI-Practitioner-Handbook.pdf\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "query = \"What are the different robustness testing tools?\"\n",
    "result = chain(query)\n",
    "print_result(result)\n",
    "# result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What are the different robustness testing tools?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['question']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'There are several robustness testing tools mentioned in the AI Practitioner Handbook, including IBM ART, TextAttack, and Microsoft CheckList. The data type and model type supported by each tool varies. IBM ART is generally used for arrays of numeric data (i.e. images, audio), but is attack specific. TextAttack is used for text, while Microsoft CheckList can be used for any arbitrary format (as the mutation functions can be user-defined). The expectation functions can also be user-defined for any data type. For more information on robustness testing tools, you can refer to Chapter 6.4.4 of the AI Practitioner Handbook. ('"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['answer']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'../pdf_data/AI-Practitioner-Handbook.pdf)'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['sources']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='tions can be user-defined). Only some text\\n\\nmutations supported in tool.\\n\\nAny for black box attacks,\\n\\nspecific model type for spe-\\n\\ncific white box attacks\\n\\nAny for black box attacks.\\n\\nspecific model type for spe-\\n\\ncific white box attacks\\n\\nAny\\n\\nTask Type (Nature\\n\\nof model output)\\n\\nAttack-specific,\\n\\nMainly classification\\n\\nClassification,\\n\\nSequence-to-\\n\\nsequence\\n\\nAny (as the expecta-\\n\\ntion functions can be\\n\\nuser-defined)\\n\\n62\\n\\nChapter 6. Modelling\\n\\nAI Practitioner Handbook\\n\\nWhen To Perform Robustness Testing?\\n\\nUsing the robustness testing tools, you can test your model in the CI/CD pipeline, at the same level as model evaluation,\\n\\nto get a good evaluation of your model. Just like unit testing or integration testing, you only need to set it up once. With\\n\\nevery new retraining, you can compare the robustness between model versions.\\n\\n6.4.4 Words of Caution\\n\\nThe goal of robustness testing is to find areas where your model does not perform, and improve on them, rather than', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       " Document(page_content='deciding whether the model is robust or not robust. There is always a need for comparison between models versions\\n\\n(especially for adversarial robustness testing). Testing the robustness of one model does not tell you anything other than\\n\\nwhere it fails. Lastly, you might find that standard accuracy might have a trade off with robustness, this is still (as of\\n\\nwriting) an area under research.\\n\\nReference(s):\\n\\nBIML Architectural Risk Analysis\\n\\nSingapore’s Model AI Governance Framework\\n\\nDeepFool\\n\\nIBM-ART\\n\\nMicrosoft CheckList\\n\\nTextAttack\\n\\nTest ML like software\\n\\nMetamorphic Testing\\n\\n6.5 How do I select classification metrics?\\n\\nContributor(s): Lee Xin Jie, Senior AI Engineer (100E), Er YuYang, Senior AI Engineer (100E)\\n\\n6.5.1 Introduction\\n\\nThe common classification evaluation metrics includes accuracy, confusion matrix, precision, recall, F1, ROC & AUC,\\n\\nprecision-recall curve.', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       " Document(page_content='There are two ways to obtain OOD data: either collect from another source, or to generate it by applying metamorphic\\n\\nmutation. Metamorphic mutation comes from software testing, where we mutate data that was inferred correctly by the\\n\\nmodel in a way that does not change the label (label-preserving mutations); eg. horizontally flip an image.\\n\\nFor text, it is slightly trickier as valid mutations depend on your model’s objective. For example, adding typos would be\\n\\na valid mutation if your model is supposed to be invariant on typos ie. not a spell checker.\\n\\nFor tabular data, mutation strategies are currently still under active research.\\n\\nRobustness Testing Tools\\n\\nHere are some tools you can try for specific types of data, model and task:\\n\\nTool\\n\\nData Type\\n\\nModel Type\\n\\nIBM ART,\\n\\nAdversarial\\n\\nGenerally arrays of numeric data (i.e. Im-\\n\\nages, Audio), but is attack specific\\n\\nTextAttack,\\n\\nAdversarial\\n\\nText\\n\\nMicrosoft\\n\\nCheck-\\n\\nList.\\n\\nadversarial\\n\\nNon-\\n\\nAny arbitrary format (as the mutation func-', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'}),\n",
       " Document(page_content='reproducibility, you can report the average performance of your model using multiple runs or even build an ensemble of\\n\\nmodels, each trained with a different random number seed. The last resort is to record down any potential stochasticity\\n\\nthat exist.\\n\\nReference(s):\\n\\nTesting for Deploying Machine Learning Models\\n\\n60\\n\\nChapter 6. Modelling\\n\\nAI Practitioner Handbook\\n\\nTesting Pipelines in Production\\n\\nAWS Whitepaper Reproducibility\\n\\nBuilding a Reproducible Machine Learning Pipeline\\n\\nReproducible AI: What it is, Why it Matters & How to Improve it?\\n\\nIntroduction to Random Number Generators for Machine Learning in Python\\n\\nEmbrace Randomness in Machine Learning\\n\\n6.4 How do I assess model robustness?\\n\\nContributor(s): Kew Wai Marn, AI Engineer\\n\\n6.4.1 Overview of Machine Learning Risks\\n\\nRisks of machine learning (ML) systems can come from data, model, and/or infrastructure. According to the architectural', metadata={'source': '../pdf_data/AI-Practitioner-Handbook.pdf'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result['source_documents']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "questionanswer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
