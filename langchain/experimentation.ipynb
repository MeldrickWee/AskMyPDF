{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.document_loaders import UnstructuredPDFLoader, OnlinePDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter, CharacterTextSplitter\n",
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "from langchain.vectorstores import FAISS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = UnstructuredPDFLoader(\"../data/pdf_data/AI-Practitioner-Handbook.pdf\")\n",
    "#loader = OnlinePDFLoader(\"https://epoch.aisingapore.org/wp-content/uploads/2023/03/AI-Practitioner-Handbook-20230324.pdf\")\n",
    "\n",
    "data = loader.load()\n",
    "print (f'You have {len(data)} document(s) in your data')\n",
    "print (f'There are {len(data[0].page_content)} characters in your document')\n",
    "\n",
    "#text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)\n",
    "texts = text_splitter.split_documents(data)\n",
    "\n",
    "print (f'Now you have {len(texts)} documents')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OPENAI_API_KEY = 'xx-xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tiktoken\n",
    "# create a GPT-4 encoder instance\n",
    "enc = tiktoken.encoding_for_model(\"gpt-3.5-turbo\")\n",
    "\n",
    "total_word_count = sum(len(doc.page_content.split()) for doc in texts)\n",
    "total_token_count = sum(len(enc.encode(doc.page_content)) for doc in texts)\n",
    "\n",
    "print(f\"\\nTotal word count: {total_word_count}\")\n",
    "print(f\"\\nEstimated tokens: {total_token_count}\")\n",
    "print(f\"\\nEstimated cost of embedding: ${total_token_count * 0.0004 / 1000}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embeddings = OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "# vector_store = FAISS.from_documents(texts, embeddings)\n",
    "\n",
    "# from IPython.display import display, Markdown\n",
    "\n",
    "# search_result = vector_store.similarity_search_with_score(\"who is this pdf for?\")\n",
    "# search_result\n",
    "\n",
    "# line_separator = \"\\n\"# {line_separator}Source: {r[0].metadata['source']}{line_separator}Score:{r[1]}{line_separator}\n",
    "# display(Markdown(f\"\"\"\n",
    "# ## Search results:{line_separator}\n",
    "# {line_separator.join([\n",
    "#   f'''\n",
    "#   ### Source:{line_separator}{r[0].metadata['source']}{line_separator}\n",
    "#   #### Score:{line_separator}{r[1]}{line_separator}\n",
    "#   #### Content:{line_separator}{r[0].page_content}{line_separator}\n",
    "#   '''\n",
    "#   for r in search_result\n",
    "# ])}\n",
    "# \"\"\"))\n",
    "\n",
    "# vector_store.save_local(\"C:/Users/meldr/aiap/langchain-question-answer/data/vector_data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts.chat import (\n",
    "    ChatPromptTemplate,\n",
    "    SystemMessagePromptTemplate,\n",
    "    HumanMessagePromptTemplate,\n",
    ")\n",
    "\n",
    "system_template=\"\"\"Use the following pieces of context to answer the users question.\n",
    "Take note of the sources and include them in the answer in the format: \"SOURCES: source1 source2\", use \"SOURCES\" in capital letters regardless of the number of sources.\n",
    "If you don't know the answer, just say that \"I don't know\", don't try to make up an answer.\n",
    "----------------\n",
    "{summaries}\"\"\"\n",
    "messages = [\n",
    "    SystemMessagePromptTemplate.from_template(system_template),\n",
    "    HumanMessagePromptTemplate.from_template(\"{question}\")\n",
    "]\n",
    "prompt = ChatPromptTemplate.from_messages(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains import RetrievalQAWithSourcesChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "path = \"C:/Users/meldr/aiap/langchain-question-answer/data/vector_data/\"\n",
    "if os.path.exists(path):\n",
    "  vector_store = FAISS.load_local(\n",
    "      path,\n",
    "      OpenAIEmbeddings(openai_api_key=OPENAI_API_KEY)\n",
    "  )\n",
    "else:\n",
    "  print(f\"Missing files. Upload index.faiss and index.pkl files to {path} directory first\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_type_kwargs = {\"prompt\": prompt}\n",
    "llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0, openai_api_key=OPENAI_API_KEY)  # Modify model_name if you have access to GPT-4\n",
    "chain = RetrievalQAWithSourcesChain.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vector_store.as_retriever(),\n",
    "    return_source_documents=True,\n",
    "    chain_type_kwargs=chain_type_kwargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Markdown\n",
    "\n",
    "def print_result(result):\n",
    "    output_text = f\"\"\"### Question: \n",
    "    {query}\n",
    "    ### Answer: \n",
    "    {result['answer']}\n",
    "    ### Sources: \n",
    "    {result['sources']}\n",
    "    ### All relevant sources:\n",
    "    {' '.join(list(set([doc.metadata['source'] for doc in result['source_documents']])))}\n",
    "    \"\"\"\n",
    "    display(Markdown(output_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the different robustness testing tools?\"\n",
    "# result = chain(query)\n",
    "print_result(result)\n",
    "# result"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
